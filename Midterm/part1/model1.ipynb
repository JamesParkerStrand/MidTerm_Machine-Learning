{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.155505100Z",
     "start_time": "2026-02-11T21:37:30.140810200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"dermatology.csv\",\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    na_values=\"?\"\n",
    ")\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "y_val = df.iloc[:,-1].to_numpy()\n",
    "X_val = df[\"Age\"].to_numpy()"
   ],
   "id": "2df3a06f98d01aa9",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.164476600Z",
     "start_time": "2026-02-11T21:37:30.157571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# splitting the data frame into train validate and test\n",
    "\n",
    "def split_train_val_test(X, y, train_size=0.7, test_size=0.3, seed = 42):\n",
    "    assert abs(train_size+ test_size - 1.0) < 1e-9\n",
    "\n",
    "    n = len(X) # Gives the number of rows\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    idx = rng.permutation(n)\n",
    "\n",
    "    n_train = int(train_size * n)\n",
    "    train_idx = idx[:n_train]\n",
    "    test_idx = idx[n_train:]\n",
    "\n",
    "    return X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n"
   ],
   "id": "7d9dcee666d0b6d7",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.174511500Z",
     "start_time": "2026-02-11T21:37:30.165068100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a gradient decent\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    y_hat = X @ theta\n",
    "    cost = (1/(2*m)) * np.sum(np.square(y_hat - y))\n",
    "\n",
    "    return float(cost)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def batch_gradient_descent(X, y, learning_rate=0.001, epsilon=1e-4, max_iteration=5):\n",
    "    \"\"\"\n",
    "    Iteratively updates the weights to minimize the cost.\n",
    "\n",
    "    :param X: The features\n",
    "    :param y: The labels\n",
    "    :param learning_rate: The step size of how much to change theta\n",
    "    :param epsilon: The convergence tolerance\n",
    "    :param max_iteration: The maximum number of iterations\n",
    "    :return: Returns a weight vector derived with batch gradient decent.\n",
    "    \"\"\"\n",
    "    # Checks if the array is 2D array.\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # Gets the m and n dimension (m,n)\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initialize theta matrix with all ones\n",
    "    theta = np.ones((n, 1), dtype=int)\n",
    "\n",
    "    costs = [compute_cost(X, y, theta)]\n",
    "    current_iteration = 0\n",
    "\n",
    "    # This section is the gradient decent\n",
    "    while current_iteration < max_iteration:\n",
    "        y_hat = X @ theta\n",
    "        diff = y_hat - y\n",
    "\n",
    "        # A vector with the same shape as theta. Gives direction of where the cost increases fastest.\n",
    "        # Large grad means the slope of the cost is steep. Small grad means the slope of the cost is flat.\n",
    "        grad = (X.T @ diff) / m\n",
    "\n",
    "        # The individual weights\n",
    "        theta = theta - learning_rate * grad\n",
    "\n",
    "        new_cost = compute_cost(X, y, theta)\n",
    "        costs.append(new_cost)\n",
    "\n",
    "        if abs(costs[-1] - costs[-2]) <= epsilon:\n",
    "            break\n",
    "\n",
    "        if costs[-1] > costs[-2]:\n",
    "            print(\"Cost is increasing â€” reduce alpha.\")\n",
    "            break\n",
    "\n",
    "        current_iteration += 1\n",
    "\n",
    "    print(\"Completed in\", current_iteration, \"iterations.\")\n",
    "    return theta, costs\n",
    "\n"
   ],
   "id": "d7a2faae29b8d1ea",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.182534Z",
     "start_time": "2026-02-11T21:37:30.175251800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imputing the values so that it replaces the nan values with the mean to not encourage biases but also not removing\n",
    "# data\n",
    "\n",
    "def impute(X):\n",
    "    \"\"\"\n",
    "    Replaces nan values with the column mean.\n",
    "\n",
    "    :param X: the X column\n",
    "    :return: new array with replaced nan values\n",
    "    \"\"\"\n",
    "    _X = []\n",
    "\n",
    "\n",
    "    num_nans = 0\n",
    "\n",
    "    for index in range(len(X)):\n",
    "        if np.isnan(X[index]):\n",
    "            num_nans+=1\n",
    "\n",
    "\n",
    "    def _get_median(x):\n",
    "        \"\"\"\n",
    "        Get the median of the column to fill in nan values.\n",
    "\n",
    "        :param x: The feature column\n",
    "        :return: The mean of the column\n",
    "        \"\"\"\n",
    "        r = [x[0]]\n",
    "        _index = 0\n",
    "        for j in range(len(x)):\n",
    "            if not np.isnan(x[j]):\n",
    "                if r[_index] > x[j]:\n",
    "                    buff = r.pop(_index)\n",
    "                    r.append(x[j])\n",
    "                    r.append(buff)\n",
    "                else:\n",
    "                    r.append(x[j])\n",
    "                _index += 1\n",
    "\n",
    "\n",
    "        return r[int(len(r)/2)]\n",
    "\n",
    "    meadian = _get_median(X)\n",
    "\n",
    "    index = 0\n",
    "    for x_val in X:\n",
    "        if np.isnan(x_val):\n",
    "            _X.append(int(meadian))\n",
    "        else:\n",
    "            _X.append(int(x_val))\n",
    "        index += 1\n",
    "\n",
    "    return np.asarray(_X)"
   ],
   "id": "ebb78cc5c3f92ca6",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b0078dfb9dd0086c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.188767900Z",
     "start_time": "2026-02-11T21:37:30.183038200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setClassifier(y_hat_vals):\n",
    "    _y = []\n",
    "    for _i in range(len(y_hat_vals)):\n",
    "        if int(y_hat_vals[_i]) == 0:\n",
    "            _y.append(1)\n",
    "        else:\n",
    "            _y.append(int(round(y_hat_vals[_i], 1)))\n",
    "\n",
    "    return _y\n"
   ],
   "id": "f570ba72cee8769b",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T21:37:30.319017Z",
     "start_time": "2026-02-11T21:37:30.188767900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "avg_acc = 0\n",
    "seed_min = 0\n",
    "seed_max = 100\n",
    "\n",
    "for i in range(seed_min, seed_max + 1, 1):\n",
    "    X_train, y_train, X_test, y_test = split_train_val_test(X_val, y_val, seed=i)\n",
    "\n",
    "    X_train = impute(X_train).reshape(-1,1)\n",
    "    X_test = impute(X_test).reshape(-1, 1)\n",
    "\n",
    "    w_hat,cost_hist = batch_gradient_descent(X_train, y_train)\n",
    "\n",
    "    yhat_test = X_test @ w_hat\n",
    "    y_pred = np.clip(np.rint(yhat_test), 1, 6).astype(int)\n",
    "\n",
    "    test_acc = np.mean(y_pred == y_test)\n",
    "\n",
    "    avg_acc += test_acc\n",
    "\n",
    "avg_acc /= (seed_max - seed_min)\n",
    "\n",
    "print(f'Test Average Accuracy: %{avg_acc * 100:.2f}')\n"
   ],
   "id": "4a4c7bcf918596aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Completed in 5 iterations.\n",
      "Test Average Accuracy: %28.65\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Report analysis (Predicting disease with Age using Batch Gradient Decent):\n",
    "The model used here to generate the prediction is the batch gradient decent.\n",
    "I split the data up 70/30 where I trained with 70% of the data set and I tested using 30% of the data set. The model\n",
    "attempted to use Age as a means to predict the type of disease, however, as you may see in the output, the accuracy\n",
    "is averages around %22.46, meaning that this is a horrible model to use for this specific data set. The parameters I\n",
    "set for the gradient decent is alpha=0.001, epsilon=1e-4, max_iters=100000. I found that with alpha values any higher\n",
    " than 0.001, the model doesn't converge.\n",
    "\n",
    "After adjusting the max number of iterations from 100000 to 5, I found that the average accuracy score went up to %28\n",
    ".65, however, that is still within the realms of the model just making random guesses.\n"
   ],
   "id": "867cd35374b739d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
